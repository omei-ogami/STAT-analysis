{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Linear Regression\n",
    "\n",
    "In this notebook, we will perform linear regression on a dataset we've just created in EDA. The objective is to build an appropriate linear regression model to tell that which hyperparameters are most important in helping the performance of the model.\n",
    "\n",
    "- Stepwise regression\n",
    "  \n",
    "- Model evaluation \n",
    "- Model interpretation\n",
    "\n",
    "> **Note**: this notebook uses R kernel to perform linear regression. If you don't have R kernel for Jupyter, you can just copy and paste the code into R console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'leaps' was built under R version 4.4.2\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 20</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>learning_rate</th><th scope=col>n_estimators</th><th scope=col>max_depth</th><th scope=col>min_child_weight</th><th scope=col>subsample</th><th scope=col>gamma</th><th scope=col>alpha</th><th scope=col>lambda</th><th scope=col>colsample_bytree</th><th scope=col>scale_pos_weight</th><th scope=col>F1</th><th scope=col>learning_rate_n_estimators</th><th scope=col>learning_rate_max_depth</th><th scope=col>n_estimators_max_depth</th><th scope=col>max_depth_subsample</th><th scope=col>alpha_lambda</th><th scope=col>max_depth_min_child_weight</th><th scope=col>scale_pos_weight_max_depth</th><th scope=col>max_depth_colsample_bytree</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0</td><td>0.11861663</td><td>915</td><td>9</td><td>5</td><td>0.9216662</td><td>0.30814537</td><td>0.6040050</td><td>0.5648192</td><td>0.9611604</td><td>3</td><td>0.8080999</td><td>108.53422</td><td>1.0675497</td><td>8235</td><td>8.294996</td><td>0.3411536</td><td>45</td><td>27</td><td>8.650444</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td>0.28570715</td><td>549</td><td>4</td><td>1</td><td>0.9465693</td><td>0.02243028</td><td>0.8713336</td><td>0.3392034</td><td>0.9257677</td><td>1</td><td>0.8185859</td><td>156.85322</td><td>1.1428286</td><td>2196</td><td>3.786277</td><td>0.2955593</td><td> 4</td><td> 4</td><td>3.703071</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>2</td><td>0.22227824</td><td>553</td><td>7</td><td>5</td><td>0.6238469</td><td>0.31127350</td><td>0.9989047</td><td>0.3226837</td><td>0.7836637</td><td>2</td><td>0.8047893</td><td>122.91987</td><td>1.5559477</td><td>3871</td><td>4.366929</td><td>0.3223303</td><td>35</td><td>14</td><td>5.485646</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>3</td><td>0.18361096</td><td>728</td><td>7</td><td>2</td><td>0.8768202</td><td>0.15445886</td><td>0.6077628</td><td>0.6449063</td><td>0.7007154</td><td>3</td><td>0.8044808</td><td>133.66878</td><td>1.2852767</td><td>5096</td><td>6.137742</td><td>0.3919501</td><td>14</td><td>21</td><td>4.905008</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>4</td><td>0.05524541</td><td>320</td><td>8</td><td>5</td><td>0.6559950</td><td>0.18436258</td><td>0.4047059</td><td>0.8514844</td><td>0.7481281</td><td>4</td><td>0.8071021</td><td> 17.67853</td><td>0.4419632</td><td>2560</td><td>5.247960</td><td>0.3446008</td><td>40</td><td>32</td><td>5.985025</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 20\n",
       "\\begin{tabular}{r|llllllllllllllllllll}\n",
       "  & X & learning\\_rate & n\\_estimators & max\\_depth & min\\_child\\_weight & subsample & gamma & alpha & lambda & colsample\\_bytree & scale\\_pos\\_weight & F1 & learning\\_rate\\_n\\_estimators & learning\\_rate\\_max\\_depth & n\\_estimators\\_max\\_depth & max\\_depth\\_subsample & alpha\\_lambda & max\\_depth\\_min\\_child\\_weight & scale\\_pos\\_weight\\_max\\_depth & max\\_depth\\_colsample\\_bytree\\\\\n",
       "  & <int> & <dbl> & <int> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <int> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 0 & 0.11861663 & 915 & 9 & 5 & 0.9216662 & 0.30814537 & 0.6040050 & 0.5648192 & 0.9611604 & 3 & 0.8080999 & 108.53422 & 1.0675497 & 8235 & 8.294996 & 0.3411536 & 45 & 27 & 8.650444\\\\\n",
       "\t2 & 1 & 0.28570715 & 549 & 4 & 1 & 0.9465693 & 0.02243028 & 0.8713336 & 0.3392034 & 0.9257677 & 1 & 0.8185859 & 156.85322 & 1.1428286 & 2196 & 3.786277 & 0.2955593 &  4 &  4 & 3.703071\\\\\n",
       "\t3 & 2 & 0.22227824 & 553 & 7 & 5 & 0.6238469 & 0.31127350 & 0.9989047 & 0.3226837 & 0.7836637 & 2 & 0.8047893 & 122.91987 & 1.5559477 & 3871 & 4.366929 & 0.3223303 & 35 & 14 & 5.485646\\\\\n",
       "\t4 & 3 & 0.18361096 & 728 & 7 & 2 & 0.8768202 & 0.15445886 & 0.6077628 & 0.6449063 & 0.7007154 & 3 & 0.8044808 & 133.66878 & 1.2852767 & 5096 & 6.137742 & 0.3919501 & 14 & 21 & 4.905008\\\\\n",
       "\t5 & 4 & 0.05524541 & 320 & 8 & 5 & 0.6559950 & 0.18436258 & 0.4047059 & 0.8514844 & 0.7481281 & 4 & 0.8071021 &  17.67853 & 0.4419632 & 2560 & 5.247960 & 0.3446008 & 40 & 32 & 5.985025\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 20\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | learning_rate &lt;dbl&gt; | n_estimators &lt;int&gt; | max_depth &lt;int&gt; | min_child_weight &lt;int&gt; | subsample &lt;dbl&gt; | gamma &lt;dbl&gt; | alpha &lt;dbl&gt; | lambda &lt;dbl&gt; | colsample_bytree &lt;dbl&gt; | scale_pos_weight &lt;int&gt; | F1 &lt;dbl&gt; | learning_rate_n_estimators &lt;dbl&gt; | learning_rate_max_depth &lt;dbl&gt; | n_estimators_max_depth &lt;int&gt; | max_depth_subsample &lt;dbl&gt; | alpha_lambda &lt;dbl&gt; | max_depth_min_child_weight &lt;int&gt; | scale_pos_weight_max_depth &lt;int&gt; | max_depth_colsample_bytree &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 0 | 0.11861663 | 915 | 9 | 5 | 0.9216662 | 0.30814537 | 0.6040050 | 0.5648192 | 0.9611604 | 3 | 0.8080999 | 108.53422 | 1.0675497 | 8235 | 8.294996 | 0.3411536 | 45 | 27 | 8.650444 |\n",
       "| 2 | 1 | 0.28570715 | 549 | 4 | 1 | 0.9465693 | 0.02243028 | 0.8713336 | 0.3392034 | 0.9257677 | 1 | 0.8185859 | 156.85322 | 1.1428286 | 2196 | 3.786277 | 0.2955593 |  4 |  4 | 3.703071 |\n",
       "| 3 | 2 | 0.22227824 | 553 | 7 | 5 | 0.6238469 | 0.31127350 | 0.9989047 | 0.3226837 | 0.7836637 | 2 | 0.8047893 | 122.91987 | 1.5559477 | 3871 | 4.366929 | 0.3223303 | 35 | 14 | 5.485646 |\n",
       "| 4 | 3 | 0.18361096 | 728 | 7 | 2 | 0.8768202 | 0.15445886 | 0.6077628 | 0.6449063 | 0.7007154 | 3 | 0.8044808 | 133.66878 | 1.2852767 | 5096 | 6.137742 | 0.3919501 | 14 | 21 | 4.905008 |\n",
       "| 5 | 4 | 0.05524541 | 320 | 8 | 5 | 0.6559950 | 0.18436258 | 0.4047059 | 0.8514844 | 0.7481281 | 4 | 0.8071021 |  17.67853 | 0.4419632 | 2560 | 5.247960 | 0.3446008 | 40 | 32 | 5.985025 |\n",
       "\n"
      ],
      "text/plain": [
       "  X learning_rate n_estimators max_depth min_child_weight subsample gamma     \n",
       "1 0 0.11861663    915          9         5                0.9216662 0.30814537\n",
       "2 1 0.28570715    549          4         1                0.9465693 0.02243028\n",
       "3 2 0.22227824    553          7         5                0.6238469 0.31127350\n",
       "4 3 0.18361096    728          7         2                0.8768202 0.15445886\n",
       "5 4 0.05524541    320          8         5                0.6559950 0.18436258\n",
       "  alpha     lambda    colsample_bytree scale_pos_weight F1       \n",
       "1 0.6040050 0.5648192 0.9611604        3                0.8080999\n",
       "2 0.8713336 0.3392034 0.9257677        1                0.8185859\n",
       "3 0.9989047 0.3226837 0.7836637        2                0.8047893\n",
       "4 0.6077628 0.6449063 0.7007154        3                0.8044808\n",
       "5 0.4047059 0.8514844 0.7481281        4                0.8071021\n",
       "  learning_rate_n_estimators learning_rate_max_depth n_estimators_max_depth\n",
       "1 108.53422                  1.0675497               8235                  \n",
       "2 156.85322                  1.1428286               2196                  \n",
       "3 122.91987                  1.5559477               3871                  \n",
       "4 133.66878                  1.2852767               5096                  \n",
       "5  17.67853                  0.4419632               2560                  \n",
       "  max_depth_subsample alpha_lambda max_depth_min_child_weight\n",
       "1 8.294996            0.3411536    45                        \n",
       "2 3.786277            0.2955593     4                        \n",
       "3 4.366929            0.3223303    35                        \n",
       "4 6.137742            0.3919501    14                        \n",
       "5 5.247960            0.3446008    40                        \n",
       "  scale_pos_weight_max_depth max_depth_colsample_bytree\n",
       "1 27                         8.650444                  \n",
       "2  4                         3.703071                  \n",
       "3 14                         5.485646                  \n",
       "4 21                         4.905008                  \n",
       "5 32                         5.985025                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(leaps)\n",
    "\n",
    "data <- read.csv(\"data/eda_data.csv\")\n",
    "head(data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepwise Regression\n",
    "\n",
    "In this section, we will use `regsubset()` function from the `leaps` package to perform stepwise regression. The `regsubset()` function takes a formula and a data frame as input and returns the best subset of variables that can be used to explain the response variable. The function uses forward selection to select the best variables, and then uses backward elimination to remove the least significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  AIC=-13918.55\n",
      "F1 ~ 1\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ learning_rate_max_depth     1  0.047710 0.089294 -14557\n",
      "+ scale_pos_weight_max_depth  1  0.041528 0.095476 -14457\n",
      "+ n_estimators_max_depth      1  0.031180 0.105823 -14303\n",
      "+ max_depth                   1  0.030940 0.106063 -14300\n",
      "+ max_depth_colsample_bytree  1  0.027796 0.109208 -14256\n",
      "+ scale_pos_weight            1  0.026032 0.110971 -14232\n",
      "+ learning_rate_n_estimators  1  0.021680 0.115323 -14174\n",
      "+ max_depth_subsample         1  0.017963 0.119041 -14127\n",
      "+ learning_rate               1  0.015738 0.121266 -14099\n",
      "+ max_depth_min_child_weight  1  0.009626 0.127377 -14026\n",
      "+ n_estimators                1  0.006369 0.130634 -13988\n",
      "+ subsample                   1  0.002573 0.134431 -13945\n",
      "+ gamma                       1  0.001414 0.135589 -13932\n",
      "+ alpha                       1  0.000313 0.136690 -13920\n",
      "<none>                                    0.137004 -13919\n",
      "+ colsample_bytree            1  0.000102 0.136902 -13918\n",
      "+ alpha_lambda                1  0.000066 0.136937 -13917\n",
      "+ min_child_weight            1  0.000032 0.136972 -13917\n",
      "+ X                           1  0.000018 0.136986 -13917\n",
      "+ lambda                      1  0.000001 0.137003 -13917\n",
      "\n",
      "Step:  AIC=-14557.38\n",
      "F1 ~ learning_rate_max_depth\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ scale_pos_weight            1  0.029388 0.059906 -15153\n",
      "+ scale_pos_weight_max_depth  1  0.024611 0.064683 -15038\n",
      "+ n_estimators_max_depth      1  0.014970 0.074324 -14830\n",
      "+ learning_rate               1  0.007952 0.081343 -14695\n",
      "+ n_estimators                1  0.006801 0.082493 -14674\n",
      "+ max_depth                   1  0.006646 0.082648 -14671\n",
      "+ max_depth_colsample_bytree  1  0.005744 0.083550 -14655\n",
      "+ subsample                   1  0.002754 0.086540 -14602\n",
      "+ max_depth_subsample         1  0.001880 0.087414 -14587\n",
      "+ max_depth_min_child_weight  1  0.001832 0.087462 -14586\n",
      "+ gamma                       1  0.001329 0.087965 -14578\n",
      "+ learning_rate_n_estimators  1  0.000736 0.088558 -14568\n",
      "+ alpha                       1  0.000441 0.088853 -14563\n",
      "<none>                                    0.089294 -14557\n",
      "+ X                           1  0.000048 0.089246 -14556\n",
      "+ alpha_lambda                1  0.000036 0.089258 -14556\n",
      "+ colsample_bytree            1  0.000011 0.089283 -14556\n",
      "+ lambda                      1  0.000011 0.089283 -14556\n",
      "+ min_child_weight            1  0.000010 0.089284 -14556\n",
      "- learning_rate_max_depth     1  0.047710 0.137004 -13919\n",
      "\n",
      "Step:  AIC=-15152.93\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ n_estimators_max_depth      1  0.014895 0.045010 -15579\n",
      "+ learning_rate               1  0.008533 0.051372 -15381\n",
      "+ max_depth                   1  0.006699 0.053207 -15328\n",
      "+ n_estimators                1  0.006240 0.053666 -15316\n",
      "+ max_depth_colsample_bytree  1  0.005910 0.053996 -15306\n",
      "+ subsample                   1  0.003097 0.056809 -15230\n",
      "+ max_depth_subsample         1  0.001805 0.058101 -15197\n",
      "+ max_depth_min_child_weight  1  0.001590 0.058316 -15191\n",
      "+ gamma                       1  0.001264 0.058642 -15183\n",
      "+ scale_pos_weight_max_depth  1  0.001100 0.058806 -15179\n",
      "+ learning_rate_n_estimators  1  0.000526 0.059379 -15164\n",
      "+ alpha                       1  0.000271 0.059635 -15158\n",
      "+ alpha_lambda                1  0.000087 0.059819 -15153\n",
      "<none>                                    0.059906 -15153\n",
      "+ colsample_bytree            1  0.000039 0.059866 -15152\n",
      "+ lambda                      1  0.000035 0.059871 -15152\n",
      "+ X                           1  0.000009 0.059897 -15151\n",
      "+ min_child_weight            1  0.000008 0.059897 -15151\n",
      "- scale_pos_weight            1  0.029388 0.089294 -14557\n",
      "- learning_rate_max_depth     1  0.051066 0.110971 -14232\n",
      "\n",
      "Step:  AIC=-15578.89\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ subsample                   1  0.002827 0.042183 -15674\n",
      "+ learning_rate               1  0.002139 0.042871 -15650\n",
      "+ n_estimators                1  0.001075 0.043935 -15613\n",
      "+ gamma                       1  0.000879 0.044131 -15606\n",
      "+ max_depth_colsample_bytree  1  0.000801 0.044209 -15604\n",
      "+ max_depth                   1  0.000652 0.044358 -15599\n",
      "+ learning_rate_n_estimators  1  0.000630 0.044380 -15598\n",
      "+ scale_pos_weight_max_depth  1  0.000401 0.044610 -15590\n",
      "+ alpha                       1  0.000261 0.044749 -15586\n",
      "+ colsample_bytree            1  0.000133 0.044877 -15581\n",
      "+ max_depth_subsample         1  0.000102 0.044909 -15580\n",
      "+ alpha_lambda                1  0.000098 0.044912 -15580\n",
      "<none>                                    0.045010 -15579\n",
      "+ min_child_weight            1  0.000049 0.044961 -15578\n",
      "+ lambda                      1  0.000038 0.044973 -15578\n",
      "+ max_depth_min_child_weight  1  0.000025 0.044985 -15578\n",
      "+ X                           1  0.000001 0.045010 -15577\n",
      "- n_estimators_max_depth      1  0.014895 0.059906 -15153\n",
      "- scale_pos_weight            1  0.029314 0.074324 -14830\n",
      "- learning_rate_max_depth     1  0.034177 0.079187 -14735\n",
      "\n",
      "Step:  AIC=-15674.01\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ learning_rate               1  0.002157 0.040026 -15751\n",
      "+ n_estimators                1  0.001096 0.041087 -15711\n",
      "+ gamma                       1  0.000981 0.041202 -15707\n",
      "+ max_depth_colsample_bytree  1  0.000766 0.041417 -15699\n",
      "+ max_depth                   1  0.000679 0.041504 -15696\n",
      "+ learning_rate_n_estimators  1  0.000617 0.041566 -15694\n",
      "+ scale_pos_weight_max_depth  1  0.000392 0.041791 -15686\n",
      "+ max_depth_subsample         1  0.000335 0.041847 -15684\n",
      "+ alpha                       1  0.000298 0.041885 -15683\n",
      "+ alpha_lambda                1  0.000126 0.042057 -15676\n",
      "+ colsample_bytree            1  0.000090 0.042093 -15675\n",
      "<none>                                    0.042183 -15674\n",
      "+ lambda                      1  0.000045 0.042138 -15674\n",
      "+ max_depth_min_child_weight  1  0.000043 0.042140 -15674\n",
      "+ min_child_weight            1  0.000025 0.042158 -15673\n",
      "+ X                           1  0.000001 0.042182 -15672\n",
      "- subsample                   1  0.002827 0.045010 -15579\n",
      "- n_estimators_max_depth      1  0.014626 0.056809 -15230\n",
      "- scale_pos_weight            1  0.029641 0.071824 -14879\n",
      "- learning_rate_max_depth     1  0.034446 0.076629 -14782\n",
      "\n",
      "Step:  AIC=-15750.56\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ scale_pos_weight_max_depth  1 0.0050226 0.035004 -15949\n",
      "+ gamma                       1 0.0009380 0.039088 -15784\n",
      "+ max_depth_subsample         1 0.0007835 0.039243 -15778\n",
      "+ learning_rate_n_estimators  1 0.0006656 0.039361 -15774\n",
      "+ max_depth                   1 0.0003137 0.039713 -15760\n",
      "+ alpha                       1 0.0002677 0.039759 -15759\n",
      "+ max_depth_min_child_weight  1 0.0001518 0.039875 -15754\n",
      "+ alpha_lambda                1 0.0001079 0.039919 -15753\n",
      "+ colsample_bytree            1 0.0000998 0.039927 -15752\n",
      "<none>                                    0.040026 -15751\n",
      "+ lambda                      1 0.0000393 0.039987 -15750\n",
      "+ min_child_weight            1 0.0000358 0.039991 -15750\n",
      "+ max_depth_colsample_bytree  1 0.0000352 0.039991 -15750\n",
      "+ X                           1 0.0000138 0.040013 -15749\n",
      "+ n_estimators                1 0.0000023 0.040024 -15749\n",
      "- learning_rate               1 0.0021565 0.042183 -15674\n",
      "- subsample                   1 0.0028446 0.042871 -15650\n",
      "- n_estimators_max_depth      1 0.0083024 0.048329 -15470\n",
      "- learning_rate_max_depth     1 0.0190436 0.059070 -15170\n",
      "- scale_pos_weight            1 0.0299689 0.069995 -14916\n",
      "\n",
      "Step:  AIC=-15949.29\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate + scale_pos_weight_max_depth\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ max_depth                   1 0.0025988 0.032405 -16063\n",
      "+ n_estimators                1 0.0019901 0.033014 -16035\n",
      "+ max_depth_colsample_bytree  1 0.0013319 0.033672 -16005\n",
      "+ max_depth_subsample         1 0.0010291 0.033975 -15992\n",
      "+ gamma                       1 0.0008379 0.034166 -15984\n",
      "+ alpha                       1 0.0002370 0.034767 -15958\n",
      "+ alpha_lambda                1 0.0001238 0.034880 -15953\n",
      "+ colsample_bytree            1 0.0001046 0.034899 -15952\n",
      "+ max_depth_min_child_weight  1 0.0000630 0.034941 -15950\n",
      "<none>                                    0.035004 -15949\n",
      "+ lambda                      1 0.0000349 0.034969 -15949\n",
      "+ learning_rate_n_estimators  1 0.0000279 0.034976 -15948\n",
      "+ X                           1 0.0000092 0.034995 -15948\n",
      "+ min_child_weight            1 0.0000044 0.034999 -15948\n",
      "- subsample                   1 0.0028253 0.037829 -15835\n",
      "- scale_pos_weight_max_depth  1 0.0050226 0.040026 -15751\n",
      "- learning_rate               1 0.0067873 0.041791 -15686\n",
      "- n_estimators_max_depth      1 0.0105873 0.045591 -15556\n",
      "- scale_pos_weight            1 0.0196432 0.054647 -15284\n",
      "- learning_rate_max_depth     1 0.0213644 0.056368 -15238\n",
      "\n",
      "Step:  AIC=-16062.77\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate + scale_pos_weight_max_depth + \n",
      "    max_depth\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ max_depth_subsample         1 0.0011610 0.031244 -16115\n",
      "+ gamma                       1 0.0008260 0.031579 -16099\n",
      "+ n_estimators                1 0.0004504 0.031955 -16082\n",
      "+ learning_rate_n_estimators  1 0.0003786 0.032026 -16078\n",
      "+ alpha                       1 0.0001832 0.032222 -16069\n",
      "+ colsample_bytree            1 0.0001318 0.032273 -16067\n",
      "+ max_depth_colsample_bytree  1 0.0000965 0.032308 -16065\n",
      "+ alpha_lambda                1 0.0000916 0.032313 -16065\n",
      "<none>                                    0.032405 -16063\n",
      "+ lambda                      1 0.0000275 0.032377 -16062\n",
      "+ X                           1 0.0000031 0.032402 -16061\n",
      "+ max_depth_min_child_weight  1 0.0000019 0.032403 -16061\n",
      "+ min_child_weight            1 0.0000001 0.032405 -16061\n",
      "- learning_rate               1 0.0016705 0.034075 -15990\n",
      "- max_depth                   1 0.0025988 0.035004 -15949\n",
      "- subsample                   1 0.0029026 0.035308 -15936\n",
      "- scale_pos_weight_max_depth  1 0.0073077 0.039713 -15760\n",
      "- learning_rate_max_depth     1 0.0078762 0.040281 -15739\n",
      "- n_estimators_max_depth      1 0.0078863 0.040291 -15739\n",
      "- scale_pos_weight            1 0.0185917 0.050997 -15386\n",
      "\n",
      "Step:  AIC=-16115.39\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate + scale_pos_weight_max_depth + \n",
      "    max_depth + max_depth_subsample\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ gamma                       1 0.0008237 0.030420 -16153\n",
      "+ n_estimators                1 0.0004470 0.030797 -16135\n",
      "+ learning_rate_n_estimators  1 0.0004421 0.030802 -16135\n",
      "+ alpha                       1 0.0001693 0.031075 -16122\n",
      "+ colsample_bytree            1 0.0001248 0.031119 -16119\n",
      "+ alpha_lambda                1 0.0000857 0.031158 -16118\n",
      "+ max_depth_colsample_bytree  1 0.0000818 0.031162 -16117\n",
      "<none>                                    0.031244 -16115\n",
      "+ lambda                      1 0.0000316 0.031212 -16115\n",
      "+ max_depth_min_child_weight  1 0.0000041 0.031240 -16114\n",
      "+ min_child_weight            1 0.0000005 0.031243 -16113\n",
      "+ X                           1 0.0000003 0.031244 -16113\n",
      "- subsample                   1 0.0002304 0.031474 -16106\n",
      "- max_depth_subsample         1 0.0011610 0.032405 -16063\n",
      "- learning_rate               1 0.0015646 0.032809 -16044\n",
      "- max_depth                   1 0.0027308 0.033975 -15992\n",
      "- scale_pos_weight_max_depth  1 0.0070485 0.038292 -15813\n",
      "- learning_rate_max_depth     1 0.0076158 0.038860 -15791\n",
      "- n_estimators_max_depth      1 0.0078190 0.039063 -15783\n",
      "- scale_pos_weight            1 0.0181540 0.049398 -15432\n",
      "\n",
      "Step:  AIC=-16153.39\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate + scale_pos_weight_max_depth + \n",
      "    max_depth + max_depth_subsample + gamma\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ n_estimators                1 0.0004701 0.029950 -16175\n",
      "+ learning_rate_n_estimators  1 0.0003946 0.030026 -16171\n",
      "+ colsample_bytree            1 0.0001478 0.030272 -16159\n",
      "+ alpha                       1 0.0001473 0.030273 -16159\n",
      "+ max_depth_colsample_bytree  1 0.0001025 0.030318 -16156\n",
      "+ alpha_lambda                1 0.0000744 0.030346 -16155\n",
      "<none>                                    0.030420 -16153\n",
      "+ lambda                      1 0.0000339 0.030386 -16153\n",
      "+ max_depth_min_child_weight  1 0.0000060 0.030414 -16152\n",
      "+ min_child_weight            1 0.0000009 0.030419 -16151\n",
      "+ X                           1 0.0000000 0.030420 -16151\n",
      "- subsample                   1 0.0002208 0.030641 -16145\n",
      "- gamma                       1 0.0008237 0.031244 -16115\n",
      "- max_depth_subsample         1 0.0011587 0.031579 -16099\n",
      "- learning_rate               1 0.0015180 0.031938 -16082\n",
      "- max_depth                   1 0.0027224 0.033143 -16027\n",
      "- scale_pos_weight_max_depth  1 0.0069546 0.037375 -15847\n",
      "- learning_rate_max_depth     1 0.0075328 0.037953 -15824\n",
      "- n_estimators_max_depth      1 0.0076011 0.038021 -15822\n",
      "- scale_pos_weight            1 0.0179949 0.048415 -15460\n",
      "\n",
      "Step:  AIC=-16174.7\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate + scale_pos_weight_max_depth + \n",
      "    max_depth + max_depth_subsample + gamma + n_estimators\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ learning_rate_n_estimators  1 0.0013097 0.028640 -16240\n",
      "+ colsample_bytree            1 0.0001402 0.029810 -16180\n",
      "+ alpha                       1 0.0001387 0.029811 -16180\n",
      "+ max_depth_colsample_bytree  1 0.0001025 0.029848 -16178\n",
      "+ alpha_lambda                1 0.0000703 0.029880 -16176\n",
      "<none>                                    0.029950 -16175\n",
      "+ lambda                      1 0.0000323 0.029918 -16174\n",
      "+ max_depth_min_child_weight  1 0.0000087 0.029941 -16173\n",
      "+ min_child_weight            1 0.0000020 0.029948 -16173\n",
      "+ X                           1 0.0000002 0.029950 -16173\n",
      "- subsample                   1 0.0002201 0.030170 -16166\n",
      "- n_estimators                1 0.0004701 0.030420 -16153\n",
      "- gamma                       1 0.0008468 0.030797 -16135\n",
      "- max_depth_subsample         1 0.0011552 0.031105 -16120\n",
      "- learning_rate               1 0.0014266 0.031377 -16107\n",
      "- max_depth                   1 0.0020399 0.031990 -16078\n",
      "- n_estimators_max_depth      1 0.0023059 0.032256 -16066\n",
      "- scale_pos_weight_max_depth  1 0.0070585 0.037009 -15860\n",
      "- learning_rate_max_depth     1 0.0073162 0.037266 -15850\n",
      "- scale_pos_weight            1 0.0182245 0.048175 -15465\n",
      "\n",
      "Step:  AIC=-16239.64\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate + scale_pos_weight_max_depth + \n",
      "    max_depth + max_depth_subsample + gamma + n_estimators + \n",
      "    learning_rate_n_estimators\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ alpha                       1 0.0001410 0.028499 -16245\n",
      "+ colsample_bytree            1 0.0001166 0.028524 -16244\n",
      "+ max_depth_colsample_bytree  1 0.0000798 0.028561 -16242\n",
      "+ alpha_lambda                1 0.0000792 0.028561 -16242\n",
      "+ lambda                      1 0.0000454 0.028595 -16240\n",
      "<none>                                    0.028640 -16240\n",
      "+ max_depth_min_child_weight  1 0.0000032 0.028637 -16238\n",
      "+ min_child_weight            1 0.0000004 0.028640 -16238\n",
      "+ X                           1 0.0000001 0.028640 -16238\n",
      "- subsample                   1 0.0002676 0.028908 -16228\n",
      "- gamma                       1 0.0007702 0.029411 -16202\n",
      "- max_depth_subsample         1 0.0012824 0.029923 -16176\n",
      "- learning_rate_n_estimators  1 0.0013097 0.029950 -16175\n",
      "- n_estimators                1 0.0013852 0.030026 -16171\n",
      "- max_depth                   1 0.0021295 0.030770 -16134\n",
      "- n_estimators_max_depth      1 0.0023921 0.031032 -16122\n",
      "- learning_rate               1 0.0027014 0.031342 -16107\n",
      "- scale_pos_weight_max_depth  1 0.0070708 0.035711 -15911\n",
      "- learning_rate_max_depth     1 0.0076258 0.036266 -15888\n",
      "- scale_pos_weight            1 0.0182520 0.046892 -15504\n",
      "\n",
      "Step:  AIC=-16245.03\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate + scale_pos_weight_max_depth + \n",
      "    max_depth + max_depth_subsample + gamma + n_estimators + \n",
      "    learning_rate_n_estimators + alpha\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "+ colsample_bytree            1 0.0001144 0.028385 -16249\n",
      "+ max_depth_colsample_bytree  1 0.0000777 0.028422 -16247\n",
      "<none>                                    0.028499 -16245\n",
      "+ lambda                      1 0.0000343 0.028465 -16245\n",
      "+ max_depth_min_child_weight  1 0.0000025 0.028497 -16243\n",
      "+ alpha_lambda                1 0.0000011 0.028498 -16243\n",
      "+ min_child_weight            1 0.0000003 0.028499 -16243\n",
      "+ X                           1 0.0000001 0.028499 -16243\n",
      "- alpha                       1 0.0001410 0.028640 -16240\n",
      "- subsample                   1 0.0002595 0.028759 -16234\n",
      "- gamma                       1 0.0007491 0.029248 -16208\n",
      "- max_depth_subsample         1 0.0012693 0.029769 -16182\n",
      "- learning_rate_n_estimators  1 0.0013120 0.029811 -16180\n",
      "- n_estimators                1 0.0013736 0.029873 -16177\n",
      "- max_depth                   1 0.0021019 0.030601 -16140\n",
      "- n_estimators_max_depth      1 0.0023781 0.030877 -16127\n",
      "- learning_rate               1 0.0027057 0.031205 -16111\n",
      "- scale_pos_weight_max_depth  1 0.0069911 0.035491 -15919\n",
      "- learning_rate_max_depth     1 0.0076467 0.036146 -15891\n",
      "- scale_pos_weight            1 0.0180847 0.046584 -15511\n",
      "\n",
      "Step:  AIC=-16249.05\n",
      "F1 ~ learning_rate_max_depth + scale_pos_weight + n_estimators_max_depth + \n",
      "    subsample + learning_rate + scale_pos_weight_max_depth + \n",
      "    max_depth + max_depth_subsample + gamma + n_estimators + \n",
      "    learning_rate_n_estimators + alpha + colsample_bytree\n",
      "\n",
      "                             Df Sum of Sq      RSS    AIC\n",
      "<none>                                    0.028385 -16249\n",
      "+ lambda                      1 0.0000320 0.028353 -16249\n",
      "+ max_depth_colsample_bytree  1 0.0000178 0.028367 -16248\n",
      "+ max_depth_min_child_weight  1 0.0000026 0.028382 -16247\n",
      "+ alpha_lambda                1 0.0000010 0.028384 -16247\n",
      "+ min_child_weight            1 0.0000004 0.028385 -16247\n",
      "+ X                           1 0.0000000 0.028385 -16247\n",
      "- colsample_bytree            1 0.0001144 0.028499 -16245\n",
      "- alpha                       1 0.0001389 0.028524 -16244\n",
      "- subsample                   1 0.0002603 0.028645 -16237\n",
      "- gamma                       1 0.0007688 0.029154 -16211\n",
      "- max_depth_subsample         1 0.0012612 0.029646 -16186\n",
      "- learning_rate_n_estimators  1 0.0012886 0.029674 -16185\n",
      "- n_estimators                1 0.0013510 0.029736 -16181\n",
      "- max_depth                   1 0.0021067 0.030492 -16144\n",
      "- n_estimators_max_depth      1 0.0023720 0.030757 -16131\n",
      "- learning_rate               1 0.0026809 0.031066 -16116\n",
      "- scale_pos_weight_max_depth  1 0.0070239 0.035409 -15920\n",
      "- learning_rate_max_depth     1 0.0076050 0.035990 -15896\n",
      "- scale_pos_weight            1 0.0181429 0.046528 -15511\n"
     ]
    }
   ],
   "source": [
    "null_model <- lm(F1 ~ 1, data = data)\n",
    "full_model <- lm(F1 ~ ., data = data)\n",
    "fit <- step(null_model,\n",
    "            scope = list(lower = null_model, upper = full_model),\n",
    "            direction = \"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = F1 ~ learning_rate_max_depth + scale_pos_weight + \n",
       "    n_estimators_max_depth + subsample + learning_rate + scale_pos_weight_max_depth + \n",
       "    max_depth + max_depth_subsample + gamma + n_estimators + \n",
       "    learning_rate_n_estimators + alpha + colsample_bytree, data = data)\n",
       "\n",
       "Residuals:\n",
       "       Min         1Q     Median         3Q        Max \n",
       "-0.0216921 -0.0028888 -0.0001722  0.0027666  0.0174918 \n",
       "\n",
       "Coefficients:\n",
       "                             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)                 8.480e-01  2.957e-03 286.768  < 2e-16 ***\n",
       "learning_rate_max_depth    -1.329e-02  6.665e-04 -19.933  < 2e-16 ***\n",
       "scale_pos_weight           -9.852e-03  3.200e-04 -30.788  < 2e-16 ***\n",
       "n_estimators_max_depth     -2.522e-06  2.265e-07 -11.132  < 2e-16 ***\n",
       "subsample                  -1.141e-02  3.095e-03  -3.687 0.000235 ***\n",
       "learning_rate               6.127e-02  5.177e-03  11.835  < 2e-16 ***\n",
       "scale_pos_weight_max_depth  9.752e-04  5.091e-05  19.156  < 2e-16 ***\n",
       "max_depth                  -4.666e-03  4.448e-04 -10.491  < 2e-16 ***\n",
       "max_depth_subsample         3.981e-03  4.904e-04   8.118 9.90e-16 ***\n",
       "gamma                       4.993e-03  7.879e-04   6.338 3.09e-10 ***\n",
       "n_estimators                1.399e-05  1.665e-06   8.401  < 2e-16 ***\n",
       "learning_rate_n_estimators -4.349e-05  5.300e-06  -8.205 4.95e-16 ***\n",
       "alpha                       1.074e-03  3.986e-04   2.693 0.007152 ** \n",
       "colsample_bytree           -2.387e-03  9.761e-04  -2.445 0.014605 *  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.004375 on 1483 degrees of freedom\n",
       "Multiple R-squared:  0.7928,\tAdjusted R-squared:  0.791 \n",
       "F-statistic: 436.5 on 13 and 1483 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Actual vs Predicted F1 Score\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 預測值\n",
    "predicted <- predict(fit, newdata = data)\n",
    "\n",
    "# 散點圖\n",
    "plot(data$F1, predicted,\n",
    "     main = \"Actual vs Predicted F1 Score\",\n",
    "     xlab = \"Actual F1 Score\",\n",
    "     ylab = \"Predicted F1 Score\",\n",
    "     pch = 16, col = \"blue\")\n",
    "abline(0, 1, col = \"red\", lwd = 2)  # 參考線\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
